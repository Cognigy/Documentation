---
title: "Manage AI Agents"
slug: "manage-ai-agents"
description: "Manage the new generation of AI Agents with Cognigy.AI. The AI Agent Management interface lets you create, edit, and delete AI Agents."
hidden: false
tags:
  - agentic ai
  - manage ai agents
---

# Manage AI Agents

[![Version badge](https://img.shields.io/badge/Updated in-v2025.20-blue.svg)](../../../../release-notes/2025.20.md)

To manage a new generation of AI Agents, Cognigy.AI introduces the _AI Agent Management_ interface,
where you can create, edit, and delete AI Agents.

## Create AI Agents

You can create an AI Agent from scratch or hire an AI Agent from the Job Market, designed for your industry, such as airlines, food services, or sales, and customize it to fit your business needs.

To create an AI Agent, select one of the following options:

- [Create from scratch](#create-from-scratch)
- [Hire from the Job Market](#hire-from-the-job-market)

### Create from Scratch

=== "GUI"
    1. In the left-side menu of the **Project** page, select **Build > AI Agents**.
    2. Click **Create AI Agent** if you are creating an AI Agent for the first time, or click **+ New AI Agent** on the **AI Agents** page if you have created at least one AI Agent before. Configure the following settings:

    ??? info "1. General Settings"
        1. In the **General Settings** step, fill in the following fields:
            - **Name** — enter a name for your AI Agent. This name will be visible to end users when the AI Agent greets them in the chat or when one AI Agent transfers the conversation to another AI Agent. For example, `Hello, my name is Sara. How can I help you?` or `Our support specialist Alex will help with this question, transferring the conversation now`.
            - **Description** — enter a description of the AI Agent that shapes its behavior and enhances its ability to understand the desired communication style. For example, describe the AI Agent as follows: `Anna works at ACME and is highly skilled at making customers feel comfortable.`
        2. In the **Avatar** section, select avatar of your choice or upload your custom one by clicking **+** next to avatars.
           You can use any image as an avatar for your AI Agent, or create a Cognigy-style avatar using the [Cognigy.AI PSD template](https://docs.cognigy.com/_assets/ai/empower/agentic-ai/Template.psd). To open and customize the template, you will need Adobe Photoshop or [Paint.net](https://www.getpaint.net/) with the [PSD plugin](https://www.psdplugin.com/) installed. The requirements for the avatar are as follows:
            - Use an alpha channel for a transparent background.
            - Set the recommended width to 136px.
            - Set the recommended height to 184px.
            - Save the file as `.png`.
            - Include `_optimized` in the file name.

    ??? info "2. Speaking Style"
        1. In the **Speaking Style** step, configure the following settings:
            - **Set up Style** — configure how the AI Agent's choice of wording is influenced by the selected speaking style, which can affect the tone and clarity of its responses:
                - **Concise/Comprehensive** — adjust the slider to the left for brief responses and to the right for detailed responses.
                - **Formal/Informal** — adjust the slider to the left for more casual and conversational responses, and to the right for professional and structured responses.
            - **Voice Configuration** — assign a specific voice to your AI Agent if you want to use your AI Agent as a voice-based assistant. To configure this setting, ensure you have installed [Voice Gateway](../../../voice-gateway/index.md) and set up the [Voice Preview](../../test/voice-preview.md) provider. Then, fill in the fields following the same process you used for [Set Session Config Node](../../build/node-reference/voice/voice-gateway/parameter-details.md):
                - **TTS Vendor** — select the text-to-speech provider for your AI Agent. This setting determines which service will convert the AI Agent's text responses into speech.
                - **TTS Language** — select the language that your AI Agent will use for speech output. Ensure this language aligns with the preferred language of the end user.
                - **TTS Voice** — select the voice from the selected TTS vendor. This setting allows you to customize the tone, gender, and style of your AI Agent's voice.
                - **TTS Label** — select the alternative name of the TTS vendor, as specified in the [Voice Gateway Self-Service Portal](../../../voice-gateway/webapp/applications.md#add-additional-tts-and-stt-vendor). If you have multiple speech services from the same vendor, use the label to specify which service to use.
                - **Disable TTS Audio Caching** — by default, this setting is deactivated. With caching enabled, previously requested TTS audio is stored in the AI Agent cache, and repeated requests for the same audio text will use the cached result instead of sending another request. With caching disabled, the AI Agent stores the TTS audio but doesn't use it; each request is sent directly to the speech provider. Note that disabling caching can increase TTS costs. For detailed information, contact your speech provider. 

    ??? info "3. Instructions"
        1. In the **Instructions** step, configure the following setting:
            - **Instructions** — provide special instructions to your AI Agent in bullet-point form. For example:
                ```txt
                 - Greet users warmly and professionally.
                 - Keep responses concise; expand only if requested.
                 - Start with a formal tone; adjust as needed.
                 - Share troubleshooting links for technical issues.
                 - Apologize if errors occur, then correct promptly.
                ```

    ??? info "4. Knowledge Store"
        1. In the **Knowledge Store** step, configure the following settings:
            - **Knowledge Store Type** — select or upload a knowledge source that the AI Agent will use to access information from the documents you provide. By accessing and understanding these knowledge bases, the AI Agent can deliver more accurate, context-aware, and helpful responses to user queries. You need to configure an [embedding model](../knowledge-ai/overview.md) to use Knowledge AI. Select one of the following options:
                - **Choose existing Knowledge Store** — select the [Knowledge Store](../knowledge-ai/knowledge-store.md) that the AI Agent will use to access information from the documents you provide.
                - **Upload Knowledge Source** — upload documents with supported formats, such as PDF, text, DOCX, PPTX, or CTXT file formats. The CTXT file format has restrictions. For more information, refer to the [CTXT](../knowledge-ai/knowledge-source/text-formats/ctxt.md) article.
                - **Upload URL Knowledge Source** — enter the URL of the web page to be used as a Knowledge Source. This type of Knowledge Source has restrictions. For more information, refer to the [Web Page](../knowledge-ai/knowledge-source/text-formats/web-page.md) article.
    ??? info "5. Data Privacy & Security"
        1. In the **Data Privacy & Security** step, configure the following fields:
            - **Contact Profile Information** — select which information the AI Agent should use from the [Cognigy Contact Profile](../../analyze/contact-profiles.md):
                - **None** — no data will be used from the Contact Profile. This option is selected by default.
                - **Selected Profile Fields** — enter specific fields from the Contact Profile for targeted data use. Specify the field using the [Profile keys](../../analyze/contact-profiles.md#profile-schema) format and press ++enter++ to apply it.
                - **Complete Profile** — use all fields from the Contact Profile to provide comprehensive user details. 
                - **Profile Memories** — use the [Memories](../../analyze/contact-profiles.md#profile-schema) field from the Contact Profile.
            - **Safety Instructions** — adjust the AI Agent's safety settings to guide content generation, interactions, and responses, ensuring compliance with ethical, legal, and operational standards. Although these settings reduce risks, occasional unexpected outputs may still occur. The selected safety instructions are included in the prompt to enhance safety, which may increase token usage. Select the safety instructions you want to apply:
                - **Avoid harmful content** — prevent generating content that could be harmful, offensive, or abusive to end users.
                - **Avoid ungrounded content** — prevent generating content that is based on speculation or unsupported claims, ensuring it is reliable and verifiable.
                - **Avoid copyright infringements** — prevent generating content that violates intellectual property rights or uses copyrighted material without authorization.
                - **Prevent jailbreak and manipulations** — prevent attempts to bypass security measures or manipulate the AI Agent into producing unauthorized or unsafe content.
    ??? info "6. Job Selection"
        1. In the **Job Selection** step, select one of the following options:
            - **Default** — create an AI Agent with a predefined Flow, then click **Create & Configure LLM** to save changes and open the Flow with the created AI Agent. If you haven't added an LLM before, the system will prompt you to [configure a model](overview.md#prerequisites) to ensure your AI-driven Flow works.
            - **Personality Only** — create an AI Agent without a predefined Flow, then click **Create** to save changes.
            - **Job** — select one of the available jobs you want to assign to the AI Agent, then click **Create** to save changes.

=== "API"
    You can create an Agent from scratch using the [Cognigy.AI API POST beta/aiagents](https://api-trial.cognigy.ai/openapi#post-/beta/aiagents) request.

### Hire from the Job Market

=== "GUI"
    1. In the left-side menu on the **Project** page, select **Build > AI Agents**.
    2. On the **AI Agents** page, click **Hire AI Agent**. The **Job Market** page displays a list of available AI Agents to hire.
    3. Hover your cursor over the desired AI Agent template and click **Hire**. This action will trigger the **Hire AI Agent** task in the Task Manager.
    4. Check the status of the **Hire AI Agent** task by clicking ![task-menu](../../../_assets/icons/task-menu.svg) in the upper-right corner.
    5. Once the task is complete, go to **Build > Flows**  and find the Flow with the AI Agent name from the template you installed.

=== "API"
    You can hire an Agent from the Job Market using the [Cognigy.AI API POST beta/aiagents/hire](https://api-trial.cognigy.ai/openapi#post-/beta/aiagents/hire) request.

## Combine Custom and Hired AI Agents

You can reassign your custom AI Agent to take on the responsibilities of the hired AI Agent.
To do this, hire an AI Agent from the Job Market
and configure their interaction by defining which functions and personality traits should be combined.
This approach lets you combine the strengths of both AI Agents: ready-made job functions from the hired AI Agent and your brand's AI Agent persona from your custom AI Agent.

To combine custom and hired AI Agents, follow these steps:

1. On the **AI Agents** page, select **+ Hire AI Agent**. The **Job Market** page displays a list of available AI Agents to hire.
2. Hover your cursor over the desired AI Agent template and click ![expand](../../../_assets/icons/expand.svg) **> Hire & Configure**.
3. In the **Select an AI Agent to Combine** window, use the search field to find an AI Agent by name, then select the AI Agent from the list.
4. Click **Combine**. This action will trigger the **Hire AI Agent** and **Merge Package** tasks in the Task Manager.
5. In the left-side menu of the **Project** page, select **Build > Flows**.
6. Select the Flow that belongs to the hired AI Agent. In the Flow, you will see an AI Agent Node with your custom AI Agent persona.

## Configure Jobs and Tools for AI Agents

When you create an AI Agent from scratch or add one from the Job Market, you can add or change jobs and tools in the AI Agent configuration.

1. Open the created AI Agent and go to the **Jobs** tab.
2. Fill in the following fields:
    - **Job Name** — enter a title for the job you want to assign to the AI Agent. For example, `Customer Support Specialist`.
    - **Job Description** — enter a description of the job that outlines the responsibilities and tasks associated with the role. For example, `Handle customer inquiries, provide product information, and resolve issues efficiently`.
    - **Instructions and Context** — provide specific instructions or guidelines that the AI Agent should follow while performing its job. For example, `Always respond politely, escalate complex issues to a human agent, and ensure customer satisfaction`.

### Configure Tools for AI Agents

In the **Tools** section, click **Add Tool** to add tools that the AI Agent can use to perform its job. Select one of the following options:

=== "Regular Tools"
    A tool is a specific task that an AI Agent can perform. The AI Agent can call to perform different tasks, such as retrieving information from a database or interacting with an external API. Fill in the following fields:
     
    ??? info "Tool"
        | Parameter   | Type          | Description                                                                                                                                          |
        |-------------|---------------|------------------------------------------------------------------------------------------------------------------------------------------------------|
        | Tool ID     | CognigyScript | Provide a meaningful name as a Tool ID. This ID can contain only letters, numbers, underscores (`_`), or dashes (`-`). For example, `update_user-1`. |
        | Description | CognigyScript | Provide a detailed description of what the tool does, when it should be used, and its parameters.                                                    |

    ??? info "Parameters"
        Configure the parameters that will be collected by the AI Agent before the tool is called. You can switch between the Graphical and JSON editors. When editing the JSON, follow the [JSON Schema specification](https://json-schema.org).
        
        | Parameter       | Type          | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |
        |-----------------|---------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
        | Use Parameters  | Toggle        | Activate this toggle to add parameters in addition to the tool name and description. The AI Agent will collect all data it needs and call a Tool with these parameters filled as arguments. These values can be accessed directly in the `input.aiAgent.toolArgs` object.                                                                                                                                                                                                                                                                                                                                                                           |
        | Name            | Text          | Specify the name of the parameter. The name should be clear and concise, and describe the purpose of the parameter.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
        | Type            | Selector      | Select a type of the parameter:<ul><li>**String** — a sequence of characters. For example, `"hello"`, `"123"`.</li><li>**Number** — a numerical value, which can be either an integer (for example,`5`) or a floating point number (for example, `3.14`).</li><li>**Boolean** — a logical value representing `true` or `false`.</li><li>**Array** — a collection of elements, which can contain multiple values of any type. For example, `["apple", "banana", "cherry"]`.</li><li>**Object** — a collection of key-value pairs, where each key is a string and the value can be of any type. For example, `{"name": "John", "age": 30}`.</li></ul> |
        | Description     | CognigyScript | Explain what parameter means by providing a brief description of the parameter's usage.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |
        | Enum (optional) | Enum          | Define a set of values that the parameter can accept. The enum restricts the input to one of the specified values, ensuring only valid options are chosen. The enum is only available for string-type parameters in the Graphical editor. For other types, use the JSON editor. May not be supported by all LLM providers.                                                                                                                                                                                                                                                                                                                          |
        | Add Parameter   | Button        | Add a new parameter.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |

    ??? info "Debug Settings"
        | Parameter                 | Type   | Description                                                                                                       |
        |---------------------------|--------|-------------------------------------------------------------------------------------------------------------------|
        | Debug Message when called | Toggle | Enable the output of a debug message when the tool is called to provide detailed information about the tool call. |

    ??? info "Advanced"
        | Parameter | Type          | Description                                                                                                                                                                                                                                                                                                                                                                       |
        |-----------|---------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
        | Condition | CognigyScript | The tool will be enabled only if the condition is evaluated as true. If false, the tool isn't part of the AI Agent's Tools within this execution. For example, when using the `unlock_account` tool, you can specify a condition like `context.accountStatus === "locked"`. This checks the value in the context, and if it is missing or different, the tool will not be enabled. |

=== "MCP Tools"
    An MCP tool connects to a remote [MCP server](https://modelcontextprotocol.io/introduction) to load tools that the AI Agent can execute. Fill in the following fields:
     
    ??? info "MCP Tool"
        | Parameter          | Type          | Description                                                                                                                                                                            |
        |--------------------|---------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
        | Name               | CognigyScript | Provide a name for the MCP connection. This name helps you identify the source of the loaded tool.                                                                                     |
        | MCP Server SSE URL | CognigyScript | Provide the URL to an SSE (Server-Sent Events) endpoint from a remote [MCP server](https://modelcontextprotocol.io/introduction). Ensure that you connect only to trusted MCP servers. |
        | Timeout            | Slider        | Set the timeout time for the MCP connection in seconds.                                                                                                                                |

    ??? info "Debug Settings"
        | Parameter             | Type   | Description                                                                                                                                                                            |
        |-----------------------|--------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
        | Debug loaded Tools    | Toggle | Enable this parameter to display a debug message with all tools loaded from the MCP server. The debug message also includes tools that have been filtered out in the Advanced section. |
        | Debug with Parameters | Toggle | Enable this parameter to include the Tool Parameters in the debug message.                                                                                                             |
        | Debug calling Tool    | Toggle | Enable the output of a debug message when the tool is called to provide detailed information about the tool call.                                                                      |

    ??? info "Advanced"
        | Parameter      | Type          | Description                                                                                                                                                                                                                                                                                                                                                                                                               |
        |----------------|---------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
        | Cache Tools    | Toggle        | Disable caching of loaded tools while developing. Ensure that caching is enabled in production for performance reasons. The caching time is 10 minutes.                                                                                                                                                                                                                                                                   |
        | Condition      | CognigyScript | The tool will be enabled only if the condition is evaluated as true. If false, the tool isn't part of the AI Agent's Tools within this execution. For example, when using the `unlock_account` tool, you can specify a condition like `context.accountStatus === "locked"`. This checks the value in the context, and if it is missing or different, the tool will not be enabled.                                        |
        | Tool Filter    | Select        | Control tool filtering by selecting one of the following options:<br>- **None** — no tool filtering is applied, and all tools are available for execution. This option is selected by default. <br> - **Whitelist** — only tools on the list are allowed for execution, while all other tools are excluded. <br> - **Blacklist** — tools on the list are excluded from execution, while all other tools remain available. |
        | Blacklist      | CognigyScript | The parameter appears if you select **Blacklist** in **Tool Filter**. Specify the tools that should be blocked from execution. Specify only one tool per field.                                                                                                                                                                                                                                                           |
        | Whitelist      | CognigyScript | This parameter appears if you select **Whitelist** in **Tool Filter**. Specify the tools you want to allow for execution. Specify only one tool per field.                                                                                                                                                                                                                                                                |
        | Custom Headers |               | Enter custom authentication headers to send with the request to the MCP server. Use the **Key** and **Value** fields to enter a header. The **Value** field supports CognigyScript. After entering the header key, new empty **Key** and **Value** fields are automatically added, in case you need to add more headers. Alternatively, you can click **Show JSON Editor** and enter the headers in the code field.                                                   |

You can add multiple tools to the AI Agent. The recommended maximum number of tools is 20.

### Configure AI Agent Settings for Each Job

Configure more settings for managing AI Agents:

??? info "Memory Handling"
    | Parameter                   | Type          | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
    |-----------------------------|---------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
    | Long-Term Memory Injection  | Selector      | Allow the AI Agent to access [Contact Profile](../../analyze/contact-profiles.md) information for the current user. Select one of the following options:<ul><li>**None** – no memory.</li><li>**Inherit from AI Agent** – use the settings specified in the [AI Agent creation settings](../../empower/agentic-ai/manage-ai-agents.md#create-ai-agents).</li><li>**Inject full Contact Profile** – use all information from the Contact Profile.</li><li>**Inject Contact Memories only** – use information only from the **Memories** field in the Contact Profile.</li><li>**Inject selected Profile fields** – use information from specific fields in the Contact Profile.</li></ul> |
    | Selected Profile Fields     | Text          | The parameter appears when the **Inject selected Profile fields** option is enabled. Enter specific fields from the Contact Profile for targeted data use. Specify the field using the [Profile keys](../../analyze/contact-profiles.md#profile-schema) format and press ++enter++ to apply it.                                                                                                                                                                                                                                                                                                                                                                                            |
    | Short-Term Memory Injection | CognigyScript | Specify a static string or a dynamic value via CognigyScript to make available to the AI Agent in the current turn.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |

??? info "Grounding Knowledge"
    | Parameter                  | Type          | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
    |----------------------------|---------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
    | Knowledge Injection        | Selector      | Use the Knowledge AI feature for the AI Agent. Select one of the following options:<ul><li>**Never** — do not use the Knowledge Stores.</li><li>**When Required** — let the AI Agent decide when querying the Knowledge Stores is required to help the user.</li><li>**Once for Each User Input** — query the Knowledge Store(s) after each user input. Note that executing a query on every user input can lead to increased costs and latency.</li></ul>                                                                                                                                                                                                                                                                                                                                                                                                                                     |
    | Use AI Agent Knowledge     | Toggle        | The parameter appears when you select either **When Required** or **Once for Each User Input**. Enable to use the Knowledge Store configured in the AI Agent. The Knowledge Store configured within the [AI Agent creation settings](../../empower/agentic-ai/manage-ai-agents.md#create-ai-agents) will be used.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |
    | Use Job Knowledge          | Toggle        | The parameter appears when you select either **When Required** or **Once for Each User Input**. Enable this option to configure a specific Knowledge Store for this particular job, allowing the AI Agent to access job-specific data or resources.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |
    | Job Knowledge Store        | Selector      | The parameter appears when you select either **When Required** or **Once for Each User Input**. The parameter appears when the **Use Job Knowledge** option is enabled. Select a specific Knowledge Store for this AI Agent's job.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |
    | Top K                      | Slider        | The parameter appears when you select either **When Required** or **Once for Each User Input**. Specify how many knowledge chunks to return. Providing more results gives the AI Agent additional context, but it also increases noise and token usage.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |
    | Source Tags                | CognigyScript | The parameter appears when you select either **When Required** or **Once for Each User Input**. The tags serve to refine the scope of your knowledge search, allowing you to include only the most pertinent sections of the knowledge base and, as a result, improve the accuracy of search outputs.<br><br>Before specifying tags, ensure that they were provided during the creation of the Knowledge Sources. Add Tags by specifying each Tag separately and pressing ++enter++. The maximum number of tags is 5.<br><br>When you specify multiple Source Tags, the Search Extract Output Node defaults to an `AND` operator, meaning it only considers Sources that have all the specified Tags. This approach ensures the search results are precise and highly relevant to the end user's query. To change this behavior, go to the **Match Types for Source Tags** parameter.          |
    | Match type for Source Tags | Select        | The parameter appears when you select either **When Required** or **Once for Each User Input**. The operator to filter Knowledge Sources by Source Tags. Select one of the following options:<ul><li>**AND** — the default value, requires all tags to match across multiple Knowledge Sources. Consider the following example: there are Knowledge Sources with Tags `S-a`, `S-b`, and `S-c`. When you use the `AND` operator to filter by `S-a` and `S-b`, only Sources with both Tags `S-a` and `S-b` will be included in the search results.</li><li>**OR** — requires at least one tag to match across multiple Knowledge Sources. Consider the following example: there are Knowledge Sources with Tags `S-a`, `S-b`, and `S-c`. When you use the `OR` operator to filter by `S-a` or `S-b`, any Source with either Tag `S-a` or `S-b` will be included in the search results.</li></ul> |
    | Generate Search Prompt     | Toggle        | The parameter appears when you select **Once for Each User Input**. This parameter is enabled by default and allows you to generate a context-aware search prompt before executing the knowledge search. Note that enabling this parameter may lead to increased cost and latency.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |

??? info "Storage and Streaming Options"
    | Parameter                   | Type          | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
    |-----------------------------|---------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
    | How to handle the result    | Select        | Determine how to handle the prompt result:<ul><li>**Store in Input** — stores the AI Agent result in the Input object. To print the prompt result, refer to the configured Context key in a Say Node or enable the **Output result immediately** option.</li><li>**Store in Context** — stores the result in the Context object. To print the prompt result, refer to the configured Context key in a Say Node or enable the **Output result immediately** option.</li><li>**Stream to Output** — streams the result directly into the output. This means that chunks coming from the prompt response will be output directly into the conversation chat as soon as a Stream Buffer Flush Token is matched, and you don't need to use the AI Agent Output Token token and Say Node. By default, this result won't be stored in either the Input or the Context. You can change this behavior by activating the **Store Copy in Input** option.</li></ul> |
    | Input Key to store Result   | CognigyScript | The parameter appears when you select either **Store in Input** or **Stream to Output**. The result is stored in the `input.aiAgentOutput` object by default. You can specify another value, but the **AI Agent Output** Token will not work if the value is changed.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
    | Context Key to store Result | CognigyScript | The parameter appears when **Store in Context** is selected. The result is stored in the `context.aiAgentOutput` object by default. You can specify another key.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |
    | Stream Buffer Flush Tokens  | Text Array    | The parameter appears when **Stream to Output** is selected. It defines tokens that trigger the stream buffer to flush to the output. The tokens can be punctuation marks or symbols, such as `\n`.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
    | Output result immediately   | Toggle        | The parameter appears when you select either **Store in Input** or **Store in Context**. This parameter allows you to output results immediately without using the Say Node and AI Agent Output token.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |
    | Store Copy in Input         | Toggle        | The parameter appears when **Stream to Output** is selected. In addition to streaming the result to the output, store a copy in the Input object by specifying a value in the **Input Key to store Result** field.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |

??? info "Voice"
    | Parameter                 | Type          | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |
    |---------------------------|---------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
    | Voice Setting             | Select        | Configure the voice settings for the AI Agent Job. This parameter determines how the AI Agent selects the voice for text-to-speech (TTS) output. Select one of the following options:<br>- **Inherit from AI Agent** — use the voice settings defined in the [AI Agent creation settings](../../empower/agentic-ai/manage-ai-agents.md#create-ai-agents).<br>- **Use Job Voice** – apply custom voice settings specific to this job, allowing the AI Agent to adapt to the particular role it performs. For example, if you create a marketing AI Agent, the voice can be more engaging, friendly, and persuasive. However, if the same AI Agent performs a different role, such as customer support, the voice might be more neutral, empathetic, and formal. |
    | TTS Vendor                | Dropdown      | Select a TTS vendor from the list or add a custom one. <br><br> Note that the AI Agent Node doesn't support **TTS Labels** to distinguish configurations from the same TTS vendor. To use **TTS Labels**, add a [Set Session Config Node](../../build/node-reference/voice/voice-gateway/set-session-config.md) before the AI Agent Node in the Flow editor.                                                                                                                                                                                                                                                                                                                                                                                                                                |
    | Custom (Vendor)           | CognigyScript | The **Custom** parameter appears when you select **Custom** from the **TTS Vendor** list. Specify the [custom TTS Vendor](../../../voice-gateway/webapp/speech-services.md#add-custom-speech-vendors). For preinstalled providers, use all lowercase letters, for example, `microsoft`, `google`, `aws`. For custom providers, use the name that you specified on the [Speech Service](../../../voice-gateway/webapp/speech-services.md) page in the Voice Gateway Self-Service Portal.                                                                                                                                                                                                                                                                      |
    | TTS Language              | Dropdown      | Define the language of the voice AI Agent output. Ensure this language aligns with the preferred language of the end user.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
    | Custom (Language)         | CognigyScript | The **Custom** parameter appears when you select **Custom** from the **TTS Language** list. Specify the language of the AI Agent output. The format depends on the option selected in the TTS vendor; check your TTS vendor documentation. The typical format is as follows: `de-DE`, `fr-FR`, `en-US`.                                                                                                                                                                                                                                                                                                                                                                                                                                                             |
    | TTS Voice                 | Dropdown      | Define the voice that should be used for the voice AI Agent output. This parameter allows you to customize the AI Agent's voice by defining its tone, gender, style, and regional specifics, making conversations more personalized and aligned with your brand and target audience.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |
    | Custom (Voice)            | CognigyScript | The **Custom** parameter appears when you select **Custom** from the **TTS Voice** list. Use this parameter to specify a custom voice, which is often required for region-specific voices. The format depends on the option selected in **TTS Vendor** and typically follows the pattern `language-region-VoiceName`. For example, `de-DE-ConradNeural` for German (Germany) male voice or `en-US-JennyNeural` for English (US) female voice.                                                                                                                                                                                                                                                                                                                       |
    | TTS Label                 | CognigyScript | The alternative name of the TTS vendor is the one you [specify in the Voice Gateway Self-Service Portal](../../../voice-gateway/webapp/applications.md#add-additional-tts-and-stt-vendor). If you have created multiple speech services from the same vendor, use the label to specify which service to use.                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
    | Disable TTS Audio Caching | Toggle        | Disables TTS audio caching.<br><br> By default, the setting is deactivated. In this case, previously requested TTS audio results are stored in the AI Agent cache. When a new TTS request is made and the audio text has been previously requested, the AI Agent retrieves the cached result instead of sending another request to the TTS provider.<br><br> When the setting is activated, the AI Agent caches TTS results but doesn't use them. In this case, each request is directly sent to your speech provider.  <br><br> Note that disabling caching can increase TTS costs. For detailed information, contact your speech provider.                                                                                                                        |

??? info "Tool Settings"
    | Parameter       | Type     | Description                                                                                                                                                                                                                                                                                                                         |
    |-----------------|----------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
    | Tool Choice     | Selector | If supported by your LLM Model, this will determine how tools should be selected by the AI Agent:<ul><li>**Auto** — tools (or none) are automatically selected by the AI Agent when needed.</li><li>**Required** — your AI Agent will always use one of its Tools.</li><li>**None** — your AI Agent won't use a tool.</li></ul>     |
    | Use Strict mode | Toggle   | When the parameter is enabled, strict mode (if supported by the LLM provider) ensures that the arguments passed to a tool call precisely match the expected parameters. Enabling this feature can help prevent errors. However, it may cause a slight delay in the response, especially during the first call after making changes. |

??? info "Image Handling"
    | Parameter            | Type     | Description                                                                                                                                                                                                                                                                                                                                |
    |----------------------|----------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
    | Process Images       | Toggle   | Enable the AI Agent to read and understand images attachments. Make sure that your LLM provider supports image processing; refer to your provider's documentation. In addition, make sure that attachments are supported by and activated in your Endpoint, for example, Webchat.                                                          |
    | Images in Transcript | Selector | Configure how images older than the last turn are handled to reduce token usage: <ul><li>**Minify** — reduces the size of these images to 512x512px.</li><li>**Drop** — excludes the images.</li><li>**Keep** — sends the max size (this option consumes more tokens).</li></ul> Limitations and token consumption depend on the LLM used. |

??? info "Advanced"
    | Parameter                  | Type     | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |
    |----------------------------|----------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
    | LLM                        | Selector | Select a model that supports the [AI Agent Node feature](../../empower/llms/model-support-by-feature.md). The selected **Default** model is the model that you specified in **Settings > Generative AI Settings** of your Project. Select the model that you [added earlier](../../empower/agentic-ai/overview.md#prerequisites) while configuring Agentic AI feature. This model will manage your AI Agent.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |
    | AI Agent Base Version      | Selector | Select the base version of the AI Agent to use:<ul><li>**Fixed Version** — select a specific version, such as `1.0`, to ensure stability and avoid potential breaking changes. Use this version in production environments or for critical workflows. The version dropdown will be updated as future versions of the AI Agent Node are released.</li><li>**Latest** — use the most recent version of the AI Agent Node. While this version ensures access to the latest features, it may cause breaking changes that require manual updates.</li></ul><br>When upgrading to a fixed version or switching to the latest, always test your AI Agent carefully to ensure it works with the selected version.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
    | Timeout                    | Number   | Define the maximum number of milliseconds to wait for a response from the LLM provider.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |
    | Maximum Completion Tokens  | Slider   | Define the maximum number of tokens that can be used during a process to manage costs. However, if the limit is set too low, the output may be incomplete, as the process could be cut off before it finishes. For example, if you set the maximum tokens to 100, the model will stop generating content once it reaches 100 tokens. This number would be roughly equal to 100 words, depending on the language and tokenization method.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |
    | Temperature                | Slider   | Define the sampling temperature, which ranges between 0 and 1. Higher values, such as 0.8, make the output more random, while lower values, such as 0.2, make it more focused and deterministic.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |
    | Include Rich Media Context | Toggle   | Controls whether _context_ is added to the prompt. In this case, _context_ refers to text extracted from rich media such as Text with Buttons, Quick Replies, an [other types](../../build/node-reference/basic/say.md#output-type). This text provides AI Agents with additional information, improving their responses.<br><br>If the [Textual Description](../../build/node-reference/basic/say.md#output-type) parameter in the Say, Question, or Optional Question Node is filled, the context is taken only from this parameter. If the **Textual Description** parameter is empty, the context is taken from the button titles and alt text in the rich media. By default, the **Include Rich Media Context** parameter is active. When this parameter is inactive, no context is added.<br><br>**Examples**:<ul><li>If **Textual Description** is filled:<p>Textual Description: `Select your preferred delivery option: Standard Delivery or Express Delivery`.</p><p>Quick Replies' buttons: `Standard Delivery`, `Express Delivery`.</p><p>Context added to the prompt: `Select your preferred delivery option: Standard Delivery or Express Delivery`.</p></li><li>If **Textual Description** is empty:<p>Textual Description: empty.</p><p>Quick Replies' buttons: `Standard Delivery`, `Express Delivery`.</p><p>Context added to the prompt: `Standard Delivery`, `Express Delivery`.</p></li><li>If **Include Rich Media Context** is inactive:<p>No context is added to the prompt.</p></li></ul> |

??? info "Error Handling"
    | Parameter                      | Type          | Description                                                                                                                                                                                                                                                                                                                                                                                                              |
    |--------------------------------|---------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
    | Log to System Logs             | Toggle        | Log errors to the system logs. They can be viewed on the [Logs](../../test/logs.md) page of your Project. The parameter is inactive by default.                                                                                                                                                                                                                                                                       |
    | Store in Input                 | Toggle        | Store errors in the Input object.                                                                                                                                                                                                                                                                                                                                                                                        |
    | Select Error Handling Approach | Select        | You can select one of the Error Handling options:<ul><li>**Stop Flow Execution** — terminate the current Flow execution.</li><li>**Continue Flow Execution** — allow the Flow to continue executing, bypassing the error and proceeding to the next steps.</li><li>**Go to Node** — redirect the workflow to a specific Node in the Flow, which can be useful for error recovery or customized error handling.</li></ul> |
    | Select Flow                    | Select        | The parameter appears when **Go to Node** is selected. Select a Flow from the available options.                                                                                                                                                                                                                                                                                                                         |
    | Select Node                    | Select        | The parameter appears when **Go to Node** is selected. Select a Node from the available options.                                                                                                                                                                                                                                                                                                                         |
    | Error Message (optional)       | CognigyScript | Add the optional message to the output if the AI Agent Node fails.                                                                                                                                                                                                                                                                                                                                                       |

??? info "Debug Settings"
    | Parameter             | Type   | Description                                                                                                                                                                                                                                                                                                                                               |
    |-----------------------|--------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
    | Log Job Execution     | Toggle | Send a debug message with the current AI Agent Job configuration. The message appears in the Interaction Panel when [debug mode](../../test/interaction-panel/chat.md#debug-mode) is enabled. The parameter is active by default.                                                                                                                      |
    | Log Knowledge Results | Toggle | Send a debug message containing the result from a knowledge search. The message appears in the Interaction Panel when [debug mode](../../test/interaction-panel/chat.md#debug-mode) is enabled. The parameter is inactive by default.                                                                                                                  |
    | Show Token Count      | Toggle | Send a debug message containing the input, output, and total token count. The message appears in the Interaction Panel when [debug mode](../../test/interaction-panel/chat.md#debug-mode) is enabled. Cognigy.AI uses the GPT-3 tokenizer algorithm, so actual token usage may vary depending on the model used. The parameter is inactive by default. |
    | Log System Prompt     | Toggle | Send a debug message containing the system prompt. The message appears in the Interaction Panel when [debug mode](../../test/interaction-panel/chat.md#debug-mode) is enabled. The parameter is inactive by default.                                                                                                                                   |
    | Log LLM Latency       | Toggle | Send a debug message containing key latency metrics for the request to the model, including the time taken for the first output and the total time to complete the request. The message appears in the Interaction Panel when [debug mode](../../test/interaction-panel/chat.md#debug-mode) is enabled. The parameter is inactive by default.          |
    | Log Tool Definitions  | Toggle | Send a debug message containing information about the configured AI Agent tools. The message appears in the Interaction Panel when [debug mode](../../test/interaction-panel/chat.md#debug-mode) is enabled. The parameter is inactive by default.                                                                                                     |

To test and refine the job settings, use the Interaction Panel on the right side of the screen.

To view the AI Agent’s Flow in detail, click **Advanced Editor** in the upper-right corner.

One AI Agent can have multiple jobs. To add another job, click **Add Job** in the bottom-left corner. Note that each job corresponds to one Flow.

## Other Operations

=== "GUI"
     You can view and delete AI Agents, and copy their Reference ID in **Build > AI Agents**.

=== "API"
    You can create, edit, and delete AI Agents using [Cognigy.AI API](https://api-trial.cognigy.ai/openapi#get-/beta/aiagents).

=== "CLI"
     You can clone and edit AI Agents using [Cognigy.AI CLI](https://github.com/Cognigy/Cognigy-CLI).

## More Information

- [Overview](overview.md)
- [AI Agent Node](../../build/node-reference/ai/ai-agent.md)
- [Getting Started](../../overview/getting-started-with-ai-agents.md)